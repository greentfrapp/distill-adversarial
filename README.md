# distill-adversarial

A working draft to be submitted to Distill for consideration.

## Breaking Neural Networks
*working title*

### Summary

This article is meant to be a review of Adversarial Examples, with the following objectives in mind:

- Going through the Fast Gradient Sign Method with examples and explaining why it works
- Discussing the notion of 'real' images occupying only a slim manifold in the space of all possible images, surrounded by adversarial images
- Going through the Boundary Attack algorithm with examples and explaining why it works
- Discussing the idea that adversarial examples can be attributed to linearity of the models and comparing relu vs tanh models
- Brief discussion of defence mechanisms